{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split \n",
    "from tensorflow import keras\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get data and format it \n",
    "df = pd.read_csv('tweets.csv', names = ['target','id','date','flag','user','text'])\n",
    "sentiment = df.pop('target').values\n",
    "tweet = df.pop('text').values\n",
    "train_labels, test_labels, train_tweets, test_tweets = train_test_split(sentiment,tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reusable formatting function\n",
    "def preprocess(arr):\n",
    "    #tokenize\n",
    "    tokenizer = Tokenizer(num_words=15_000, oov_token='<UNK>', split = ' ')\n",
    "    tokenizer.fit_on_texts(arr)\n",
    "\n",
    "    #index\n",
    "    word_index = tokenizer.word_index\n",
    "\n",
    "    #sequence\n",
    "    sequences = tokenizer.texts_to_sequences(arr)\n",
    "\n",
    "    #find max sequence length\n",
    "    maxlen = max([len(x) for x in sequences])\n",
    "\n",
    "    #padding \n",
    "    train_padded = pad_sequences(sequences, padding='post', truncating='post', maxlen=maxlen)\n",
    "    \n",
    "    return train_padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocess \n",
    "test_labels = test_labels[:15_000]\n",
    "train_labels = train_labels[:15_000]\n",
    "train_tweets = train_tweets[:15_000]\n",
    "test_tweets = test_tweets[:15_000]\n",
    "train_tweets = preprocess(train_tweets)\n",
    "test_tweets = preprocess(test_tweets)\n",
    "test_labels = test_labels/2\n",
    "train_labels = train_labels/2\n",
    "test_labels = test_labels.reshape([-1, 1])\n",
    "train_labels = train_labels.reshape([-1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Embedding(15_000, 20))\n",
    "model.add(keras.layers.LSTM(256))\n",
    "#model.add(keras.layers.GlobalAveragePooling1D())\n",
    "model.add(keras.layers.Dense(50, activation = \"relu\"))\n",
    "#model.add(keras.layers.Dropout(0.2))\n",
    "model.add(keras.layers.Dense(3, activation = \"softmax\"))\n",
    "\n",
    "model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 12000 samples, validate on 3000 samples\n",
      "Epoch 1/5\n",
      "12000/12000 [==============================] - 67s 6ms/sample - loss: 0.5322 - accuracy: 0.8002 - val_loss: 0.5023 - val_accuracy: 0.7993\n",
      "Epoch 2/5\n",
      "12000/12000 [==============================] - 64s 5ms/sample - loss: 0.4991 - accuracy: 0.8036 - val_loss: 0.5066 - val_accuracy: 0.7993\n",
      "Epoch 3/5\n",
      "12000/12000 [==============================] - 64s 5ms/sample - loss: 0.4996 - accuracy: 0.8036 - val_loss: 0.5040 - val_accuracy: 0.7993\n",
      "Epoch 4/5\n",
      "12000/12000 [==============================] - 66s 5ms/sample - loss: 0.4979 - accuracy: 0.8036 - val_loss: 0.5082 - val_accuracy: 0.7993\n",
      "Epoch 5/5\n",
      "12000/12000 [==============================] - 63s 5ms/sample - loss: 0.4909 - accuracy: 0.8045 - val_loss: 0.4878 - val_accuracy: 0.8010\n"
     ]
    }
   ],
   "source": [
    "fitmodel = model.fit(train_tweets, train_labels, epochs = 5, batch_size = 50, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('twittersent_sparsecat.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.load_weights('twittersent_sparsecat.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(test_tweets, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user = 'good'\n",
    "while (user != 'stop'):\n",
    "    print(\"copy paste a tweet and i'll tell you it's sentiment. Type 'stop' at any time to stop the program. \")\n",
    "    user = str(input()).lower()\n",
    "    user = preprocess(user)\n",
    "    prediction = model.predict(user)\n",
    "    sentiment0 = np.amax(prediction[0])\n",
    "    sentiment1 = np.amax(prediction[1])\n",
    "    sentiment2 = np.amax(prediction[2])\n",
    "    if sentiment0 > sentiment1 and sentiment0 > sentiment2:\n",
    "        print(\"this is a negative comment\")\n",
    "    elif sentiment1 > sentiment0 and sentiment1 > sentiment2:\n",
    "        print(\"this is a neutral comment\")\n",
    "    elif sentiment2 > sentiment1 and sentiment2 > sentiment0:\n",
    "        print(\"this is a positive comment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
